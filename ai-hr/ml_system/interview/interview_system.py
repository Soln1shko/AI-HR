"""
–ê–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω—Ç–µ—Ä–≤—å—é
–ü–µ—Ä–µ–ø–∏—Å–∞–Ω–∞ –≤ –≤–∏–¥–µ –∫–ª–∞—Å—Å–∞ –¥–ª—è –ª—É—á—à–µ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∫–æ–¥–∞
"""
from langchain_openai import ChatOpenAI
import os
import json
import logging
from typing import Dict, Optional, Set, Any
from ml_system.retrieva import InterviewKnowledgeSystemHF, InterviewAssistantHF
from ml_system.interview.state import InterviewState
from ml_system.interview.agents.controller import AdaptiveInterviewControllerAgent
from ml_system.interview.src.config import InterviewConfig
from ml_system.interview.agents.planner import plan_interview
from ml_system.interview.agents.selector import get_fallback_question, get_resume_question, select_next_question
from ml_system.interview.agents.conversation import conversation_turn
from ml_system.interview.agents.evaluator import evaluate_answer
from ml_system.interview.src.prompts import get_report_prompt
from ml_system.interview.workflow import build_graph

logger = logging.getLogger(__name__)

class InterviewSystem:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –∏–Ω—Ç–µ—Ä–≤—å—é"""
    
    def __init__(self, 
                 api_key: str, 
                 model: str = "mistralai/mistral-7b-instruct",
                 max_total_questions: int = 2,
                 max_questions_per_topic: int = 1,
                 collection_name: str = "interview_questions_hf",
                 config: InterviewConfig | None = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –∏–Ω—Ç–µ—Ä–≤—å—é
        
        Args:
            api_key: API –∫–ª—é—á –¥–ª—è OpenRouter
            model: –ú–æ–¥–µ–ª—å LLM –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            max_total_questions: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤
            max_questions_per_topic: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –≤ –æ–¥–Ω–æ–π —Ç–µ–º–µ
        """
        if not api_key or "your" in api_key.lower() or len(api_key) < 10:
            raise ValueError("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π API –∫–ª—é—á OpenRouter.")
        
        api_key = api_key.strip()
        if len(api_key) > 200:
            logger.warning("API –∫–ª—é—á –∫–∞–∂–µ—Ç—Å—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º, –æ–±—Ä–µ–∑–∞–µ–º")
            api_key = api_key[:200]
        
        self.api_key = api_key
        self.config = config or InterviewConfig(
            model=InterviewConfig.model,
            max_total_questions=InterviewConfig.max_total_questions,
            max_questions_per_topic=InterviewConfig.max_questions_per_topic,
            collection_name=InterviewConfig.collection_name,
        )

        env_model = os.getenv("OPENROUTER_MODEL", "").strip()
        if env_model:
            self.config.model = env_model
        if isinstance(self.config.model, str) and self.config.model.endswith(":free"):
            logger.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å —Å ':free' ‚Äî —É–±–∏—Ä–∞—é —Å—É—Ñ—Ñ–∏–∫—Å, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å 429 –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞")
            self.config.model = self.config.model.split(":")[0]

        self.model = self.config.model
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å: {self.model}")
        self.max_total_questions = self.config.max_total_questions
        logger.info(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {self.max_total_questions}")
        self.max_questions_per_topic = self.config.max_questions_per_topic
        logger.info(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ —Ç–µ–º—É: {self.max_questions_per_topic}")
        self.collection_name = self.config.collection_name
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é: {self.collection_name}")
        
        try:
            self.llm = ChatOpenAI(
                model=self.config.model,
                temperature=self.config.temperature,
                api_key=api_key,
                base_url=self.config.base_url,
                timeout=self.config.request_timeout_seconds,
                max_retries=self.config.llm_max_retries,
                model_kwargs={
                    "extra_headers": {
                        "HTTP-Referer": "http://localhost",
                        "X-Title": "AI-HR Interview System"
                    }
                }
            )
            logger.info("LLM —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            logger.exception(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LLM: {e}")
            logger.debug("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å API –∫–ª—é—á –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å")
            raise
        
        self.knowledge_system = InterviewKnowledgeSystemHF(collection_name=self.collection_name)
        self.assistant = InterviewAssistantHF(knowledge_system=self.knowledge_system)
        
        self.alignment = self.config.alignment
        
        self.adaptive_controller = AdaptiveInterviewControllerAgent(
            self.llm,
            max_poor_answers=self.config.max_poor_answers,
            max_medium_answers=self.config.max_medium_answers,
            max_deepening_questions=self.config.max_deepening_questions,
            max_hints=self.config.max_hints,
            alignment=self.alignment,
        )
        
        self.workflow = None
        self.app = None
        
        logger.info("–°–∏—Å—Ç–µ–º–∞ –∏–Ω—Ç–µ—Ä–≤—å—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def _interview_planner(self, state: InterviewState) -> Dict[str, Any]:
        """–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∏–Ω—Ç–µ—Ä–≤—å—é (–æ–±—ë—Ä—Ç–∫–∞)."""
        return plan_interview(
            state,
            llm=self.llm,
            alignment=self.alignment,
            max_total_questions=self.max_total_questions,
            max_questions_per_topic=self.max_questions_per_topic,
        )
    
    def _question_selector(self, state: InterviewState) -> Dict[str, Any]:
        """–°–µ–ª–µ–∫—Ç–æ—Ä –≤–æ–ø—Ä–æ—Å–æ–≤ (–æ–±—ë—Ä—Ç–∫–∞)."""
        return select_next_question(
            state,
            assistant=self.assistant,
            llm=self.llm,
            alignment=self.alignment,
            max_questions_per_topic=self.max_questions_per_topic,
        )
    
    def _get_resume_questions(self, state: Dict[str, Any], topic: str, current_index: int, asked_questions: Set[str]) -> Dict[str, Any]:
        """–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏: –¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –ª–æ–≥–∏–∫—É –≤ selector.get_resume_question."""
        return get_resume_question(
            state,
            llm=self.llm,
            alignment=self.alignment,
            max_questions_per_topic=self.max_questions_per_topic,
            topic=topic,
            current_index=current_index,
            asked_questions=asked_questions,
        )
    
    def _get_fallback_question(self, topic: str, current_index: int, asked_questions: Set[str], questions_in_topic: int) -> Dict[str, Any]:
        """–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏: –¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –ª–æ–≥–∏–∫—É –≤ selector.get_fallback_question."""
        return get_fallback_question(topic, current_index, asked_questions, questions_in_topic)
    
    def _conversation_manager(self, state: InterviewState) -> Dict[str, Any]:
        """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–∏–∞–ª–æ–≥–∞ (–æ–±—ë—Ä—Ç–∫–∞)."""
        return conversation_turn(state)
    
    def _answer_evaluator(self, state: InterviewState) -> Dict[str, Any]:
        """–û—Ü–µ–Ω—â–∏–∫ –æ—Ç–≤–µ—Ç–æ–≤ (–æ–±—ë—Ä—Ç–∫–∞)."""
        return evaluate_answer(state, llm=self.llm, alignment=self.alignment)

    def _report_generator(self, state: InterviewState) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á—ë—Ç–æ–≤. –§–æ—Ä–º–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç –ø–æ –∏–Ω—Ç–µ—Ä–≤—å—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ü–µ–Ω–æ–∫."""
        logger.debug("--- –ê–≥–µ–Ω—Ç: –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤ ---")

        evaluations = state.get("answer_evaluations", [])
        if not evaluations:
            return {"report": "–û—Ç—á–µ—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω: –Ω–µ—Ç –æ—Ü–µ–Ω–æ–∫."}

        interview_data = {
            "resume": state.get("resume", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"),
            "job_description": state.get("job_description", "–ù–µ —É–∫–∞–∑–∞–Ω–∞"),
            "evaluations": evaluations,
        }

        topics_summary = ""
        total_score = 0
        all_inconsistencies = []
        all_red_flags = []
        all_strengths = []
        all_weaknesses = []

        for eval_item in evaluations:
            topic = eval_item.get('topic', 'Unknown')
            score = eval_item.get('score_percent', 0)
            detailed_scores = eval_item.get('detailed_scores', {})
            analysis = eval_item.get('analysis', {})

            topics_summary += f"\n‚Ä¢ –¢–µ–º–∞: {topic}\n"
            topics_summary += f"  - –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞: {score:.1f}%\n"

            if detailed_scores:
                topics_summary += f"  - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {detailed_scores.get('technical_accuracy', 'N/A')}/10\n"
                topics_summary += f"  - –ì–ª—É–±–∏–Ω–∞ –∑–Ω–∞–Ω–∏–π: {detailed_scores.get('depth_of_knowledge', 'N/A')}/10\n"
                topics_summary += f"  - –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç: {detailed_scores.get('practical_experience', 'N/A')}/10\n"
                topics_summary += f"  - –ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è: {detailed_scores.get('communication_clarity', 'N/A')}/10\n"

            all_inconsistencies.extend(analysis.get('inconsistencies', []))
            all_red_flags.extend(analysis.get('red_flags', []))
            all_strengths.extend(analysis.get('strengths', []))
            all_weaknesses.extend(analysis.get('weaknesses', []))

            total_score += score

        avg_score = total_score / len(evaluations)

        report_prompt = get_report_prompt()

        try:
            report_chain = report_prompt | self.llm
            response = report_chain.invoke({
                "resume": interview_data["resume"][:500] + "..." if len(interview_data["resume"]) > 500 else interview_data["resume"],
                "job_description": interview_data["job_description"][:300] + "..." if len(interview_data["job_description"]) > 300 else interview_data["job_description"],
                "topics_summary": topics_summary,
                "avg_score": avg_score,
                "inconsistencies": all_inconsistencies[:10],
                "red_flags": all_red_flags[:10],
                "strengths": list(set(all_strengths))[:10],
                "weaknesses": list(set(all_weaknesses))[:10]
            })
        except Exception as e:
            logger.exception(f"–û—à–∏–±–∫–∞ LLM –≤ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ –æ—Ç—á–µ—Ç–æ–≤: {e}")
            logger.warning("–ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –æ—Ç—á–µ—Ç")
            recommendation = "HIRE" if avg_score >= 80 else "MAYBE" if avg_score >= 65 else "REJECT"
            llm_analysis = {
                "overall_assessment": f"–ö–∞–Ω–¥–∏–¥–∞—Ç –ø–æ–∫–∞–∑–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç {avg_score:.1f}% –ø–æ –∏—Ç–æ–≥–∞–º –∏–Ω—Ç–µ—Ä–≤—å—é.",
                "strong_points": ["–£—á–∞—Å—Ç–≤–æ–≤–∞–ª –≤ –∏–Ω—Ç–µ—Ä–≤—å—é", "–û—Ç–≤–µ—Ç–∏–ª –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã"],
                "weak_points": ["–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞"],
                "hire_decision": recommendation,
                "hire_reasoning": f"–†–µ—à–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ —Å—Ä–µ–¥–Ω–µ–π –æ—Ü–µ–Ω–∫–µ {avg_score:.1f}%",
                "development_recommendations": ["–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –ø–æ –ø—Ä–æ—Ñ–∏–ª—å–Ω—ã–º —Ç–µ–º–∞–º"],
                "next_steps": "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ"
            }

            final_report = f"""
–û–¢–ß–ï–¢ –ü–û –ò–ù–¢–ï–†–í–¨–Æ


üéØ –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê: {avg_score:.1f}%
üìã –†–ï–®–ï–ù–ò–ï: {llm_analysis.get('hire_decision', 'UNKNOWN')}


üìÑ –û–ë–©–ê–Ø –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ê:{llm_analysis.get('overall_assessment', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}


‚úÖ –°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´:
{chr(10).join(f"  -  {point}" for point in llm_analysis.get('strong_points', ['–ù–µ —É–∫–∞–∑–∞–Ω—ã']))}


‚ö†Ô∏è  –û–ë–õ–ê–°–¢–ò –î–õ–Ø –†–ê–ó–í–ò–¢–ò–Ø:
{chr(10).join(f"  -  {point}" for point in llm_analysis.get('weak_points', ['–ù–µ —É–∫–∞–∑–∞–Ω—ã']))}


üîß –¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ö–û–ú–ü–ï–¢–ï–ù–¢–ù–û–°–¢–¨:
{llm_analysis.get('technical_competence', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}


üîç –ê–ù–ê–õ–ò–ó –ù–ï–°–û–°–¢–´–ö–û–í–û–ö:
{llm_analysis.get('inconsistencies_analysis', '–ù–µ –Ω–∞–π–¥–µ–Ω—ã')}


üö® –ê–ù–ê–õ–ò–ó –ö–†–ê–°–ù–´–• –§–õ–ê–ì–û–í:
{llm_analysis.get('red_flags_analysis', '–ù–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã')}


üìö –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –†–ê–ó–í–ò–¢–ò–Æ:
{chr(10).join(f"  -  {rec}" for rec in llm_analysis.get('development_recommendations', ['–ù–µ —É–∫–∞–∑–∞–Ω—ã']))}


üíº –û–ë–û–°–ù–û–í–ê–ù–ò–ï –†–ï–®–ï–ù–ò–Ø:
{llm_analysis.get('hire_reasoning', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}


‚ö†Ô∏è  –û–¶–ï–ù–ö–ê –†–ò–°–ö–û–í:
{llm_analysis.get('risk_assessment', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}


üöÄ –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:
{llm_analysis.get('next_steps', '–ù–µ —É–∫–∞–∑–∞–Ω—ã')}


–î–ï–¢–ê–õ–ò–ó–ê–¶–ò–Ø –ü–û –¢–ï–ú–ê–ú
{topics_summary}
""".strip()

            logger.info(f"–°–æ–∑–¥–∞–Ω –±–∞–∑–æ–≤—ã–π –æ—Ç—á–µ—Ç —Å —Ä–µ—à–µ–Ω–∏–µ–º: {llm_analysis.get('hire_decision', 'UNKNOWN')}")

            return {
                "report": final_report,
                "final_recommendation": llm_analysis.get('hire_decision', 'UNKNOWN'),
                "llm_analysis": llm_analysis,
            }

        response_content = getattr(response, "content", "")

        try:
            if "```json" in response_content:
                json_part = response_content.split("```json", 1)[1]
                json_text = json_part.split("```", 1)[0].strip()
            else:
                json_text = response_content.strip()

            llm_analysis = json.loads(json_text)
            logger.info("LLM-–∞–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω")

        except (json.JSONDecodeError, IndexError) as e:
            logger.exception(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ LLM-–æ—Ç—á–µ—Ç–∞ ({e}). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤—ã–π –æ—Ç—á–µ—Ç.")
            recommendation = "HIRE" if avg_score >= 80 else "MAYBE" if avg_score >= 65 else "REJECT"
            llm_analysis = {
                "overall_assessment": f"–ö–∞–Ω–¥–∏–¥–∞—Ç –ø–æ–∫–∞–∑–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç {avg_score:.1f}% –ø–æ –∏—Ç–æ–≥–∞–º –∏–Ω—Ç–µ—Ä–≤—å—é.",
                "strong_points": ["–£—á–∞—Å—Ç–≤–æ–≤–∞–ª –≤ –∏–Ω—Ç–µ—Ä–≤—å—é", "–û—Ç–≤–µ—Ç–∏–ª –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã"],
                "weak_points": ["–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞"],
                "hire_decision": recommendation,
                "hire_reasoning": f"–†–µ—à–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ —Å—Ä–µ–¥–Ω–µ–π –æ—Ü–µ–Ω–∫–µ {avg_score:.1f}%",
                "development_recommendations": ["–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –ø–æ –ø—Ä–æ—Ñ–∏–ª—å–Ω—ã–º —Ç–µ–º–∞–º"],
                "next_steps": "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ"
            }

        final_report = f"""
–û–¢–ß–ï–¢ –ü–û –ò–ù–¢–ï–†–í–¨–Æ


üéØ –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê: {avg_score:.1f}%
üìã –†–ï–®–ï–ù–ò–ï: {llm_analysis.get('hire_decision', 'UNKNOWN')}


üìÑ –û–ë–©–ê–Ø –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ê:{llm_analysis.get('overall_assessment', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}


‚úÖ –°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´:
{chr(10).join(f"  -  {point}" for point in llm_analysis.get('strong_points', ['–ù–µ —É–∫–∞–∑–∞–Ω—ã']))}


‚ö†Ô∏è  –û–ë–õ–ê–°–¢–ò –î–õ–Ø –†–ê–ó–í–ò–¢–ò–Ø:
{chr(10).join(f"  -  {point}" for point in llm_analysis.get('weak_points', ['–ù–µ —É–∫–∞–∑–∞–Ω—ã']))}


üîß –¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ö–û–ú–ü–ï–¢–ï–ù–¢–ù–û–°–¢–¨:
{llm_analysis.get('technical_competence', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}


üîç –ê–ù–ê–õ–ò–ó –ù–ï–°–û–°–¢–´–ö–û–í–û–ö:
{llm_analysis.get('inconsistencies_analysis', '–ù–µ –Ω–∞–π–¥–µ–Ω—ã')}


üö® –ê–ù–ê–õ–ò–ó –ö–†–ê–°–ù–´–• –§–õ–ê–ì–û–í:
{llm_analysis.get('red_flags_analysis', '–ù–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã')}


üìö –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –†–ê–ó–í–ò–¢–ò–Æ:
{chr(10).join(f"  -  {rec}" for rec in llm_analysis.get('development_recommendations', ['–ù–µ —É–∫–∞–∑–∞–Ω—ã']))}


üíº –û–ë–û–°–ù–û–í–ê–ù–ò–ï –†–ï–®–ï–ù–ò–Ø:
{llm_analysis.get('hire_reasoning', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}


‚ö†Ô∏è  –û–¶–ï–ù–ö–ê –†–ò–°–ö–û–í:
{llm_analysis.get('risk_assessment', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}


üöÄ –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:
{llm_analysis.get('next_steps', '–ù–µ —É–∫–∞–∑–∞–Ω—ã')}


–î–ï–¢–ê–õ–ò–ó–ê–¶–ò–Ø –ü–û –¢–ï–ú–ê–ú
{topics_summary}
""".strip()

        logger.info(f"–°–æ–∑–¥–∞–Ω –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å —Ä–µ—à–µ–Ω–∏–µ–º: {llm_analysis.get('hire_decision', 'UNKNOWN')}")

        return {
            "report": final_report,
            "final_recommendation": llm_analysis.get('hire_decision', 'UNKNOWN'),
            "llm_analysis": llm_analysis,
        }
    
    def _router(self, state: InterviewState) -> str:
        """–†–æ—É—Ç–µ—Ä —à–∞–≥–∞ –≥—Ä–∞—Ñ–∞: –≤—ã–±–∏—Ä–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —É–∑–µ–ª –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è."""
        logger.debug("--- –†–æ—É—Ç–µ—Ä ---")
        
        controller_decision = state.get("controller_decision")
        generated_question = state.get("generated_question")
        skip_topic = state.get("skip_topic", False)
        
        logger.debug(f"–†–µ—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞: {controller_decision}")
        logger.debug(f"–ï—Å—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å: {bool(generated_question)}")
        logger.debug(f"–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ç–µ–º—É: {skip_topic}")
        
        interview_plan = state.get("interview_plan", {})
        max_total_questions = interview_plan.get("max_total_questions", 20)
        questions_asked = state.get("questions_asked_count", 0)
        topics = interview_plan.get("topics", [])
        current_topic_index = state.get("current_topic_index", 0)
        
        deepening_count = state.get("deepening_questions_count", 0)
        hints_count = state.get("hints_given_count", 0)
        max_deepening = self.adaptive_controller.max_deepening_questions
        max_hints = self.adaptive_controller.max_hints
        logger.debug(f"–í–æ–ø—Ä–æ—Å–æ–≤ –∑–∞–¥–∞–Ω–æ: {questions_asked}/{max_total_questions}")
        logger.debug(f"–¢–µ–∫—É—â–∞—è —Ç–µ–º–∞: {current_topic_index}/{len(topics)}")
        logger.debug(f"–£—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤: {deepening_count}/{max_deepening}")
        logger.debug(f"–ü–æ–¥—Å–∫–∞–∑–æ–∫ –¥–∞–Ω–æ: {hints_count}/{max_hints}")
        logger.debug("–û–¢–õ–ê–î–ö–ê –°–ß–ï–¢–ß–ò–ö–û–í –í –†–û–£–¢–ï–†–ï:")
        logger.debug(f" - questions_asked_count: {questions_asked}")
        logger.debug(f" - deepening_questions_count: {deepening_count}")
        logger.debug(f" - hints_given_count: {hints_count}")
        
        if questions_asked >= max_total_questions:
            logger.info("–î–æ—Å—Ç–∏–≥–Ω—É—Ç –æ–±—â–∏–π –ª–∏–º–∏—Ç –≤–æ–ø—Ä–æ—Å–æ–≤")
            return "reporter"
        
        if current_topic_index >= len(topics):
            logger.info("–í—Å–µ —Ç–µ–º—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã")
            return "reporter"
        
        if questions_asked > 0 and questions_asked % 10 == 0:
            logger.warning(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –∑–∞–¥–∞–Ω–æ {questions_asked} –≤–æ–ø—Ä–æ—Å–æ–≤, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ...")
            if questions_asked >= 25:
                logger.error("–ê–≤–∞—Ä–∏–π–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ - —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤")
                return "reporter"
        
        if controller_decision == "continue_topic" and generated_question:
            logger.debug("–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–æ–º –≤–æ–ø—Ä–æ—Å")
            return "conversation_manager"
        elif controller_decision == "skip_topic" or skip_topic:
            logger.info("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ–º—É")
            return "selector"
        elif controller_decision == "continue_standard":
            logger.debug("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ—Ç–æ–∫ –∫ —Å–ª–µ–¥—É—é—â–µ–π —Ç–µ–º–µ")
            return "selector"
        
        logger.debug("–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ª–æ–≥–∏–∫–∞ - –∫ —Å–ª–µ–¥—É—é—â–µ–π —Ç–µ–º–µ")
        return "selector"
    
    def _adaptive_controller_node(self, state: InterviewState) -> Dict[str, Any]:
        """–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞."""
        return self.adaptive_controller.execute(state)
    
    def build_workflow(self) -> None:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –∏–Ω—Ç–µ—Ä–≤—å—é (—á–µ—Ä–µ–∑ workflow.build_graph)."""
        self.app = build_graph(
            planner_node=self._interview_planner,
            selector_node=self._question_selector,
            conversation_node=self._conversation_manager,
            evaluator_node=self._answer_evaluator,
            controller_node=self._adaptive_controller_node,
            reporter_node=self._report_generator,
            router_func=self._router,
        )
    
    def load_knowledge(self, knowledge_file: Optional[str] = None, knowledge_json: Optional[Dict[str, Any]] = None) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –≤ RAG-—Ö—Ä–∞–Ω–∏–ª–∏—â–µ."""
        try:
            if knowledge_file is not None:
                with open(knowledge_file, 'r', encoding='utf-8') as f:
                    knowledge_chunks = json.load(f)
            else:
                knowledge_chunks = knowledge_json
            self.knowledge_system.add_knowledge_to_rag(knowledge_chunks)
            logger.info(f"–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {knowledge_file}")
        except FileNotFoundError:
            logger.warning(f"–§–∞–π–ª {knowledge_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. RAG-—Å–∏—Å—Ç–µ–º–∞ –±—É–¥–µ—Ç –ø—É—Å—Ç–∞.")
            self.knowledge_system.add_knowledge_to_rag([{
                "section": "Python", 
                "question": "–†–∞–∑–Ω–∏—Ü–∞ list/tuple", 
                "grade": "middle",
                "answers": {
                    "expected_answer": "...", 
                    "junior_level": "...", 
                    "middle_level": "...", 
                    "senior_level": "...", 
                    "red_flags": [], 
                    "follow_up_questions": []
                }
            }])
    
    def run_interview(self, resume: str, job_description: str, role: str = "") -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–≤—å—é
        
        Args:
            resume: –†–µ–∑—é–º–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
            job_description: –û–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏
            role: –¶–µ–ª–µ–≤–∞—è —Ä–æ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, "UX/UI Designer", "ML Engineer")
            
        Returns:
            –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤—å—é
        """
        if not self.app:
            self.build_workflow()
        
        initial_state = {
            "resume": resume,
            "job_description": job_description,
            "role": role,
            "messages": [],
            "questions_asked_count": 0,
            "questions_in_current_topic": 0,
            "deepening_questions_count": 0,
            "hints_given_count": 0,
            "current_topic_index": 0,
            "answer_evaluations": [],
            "asked_question_ids": set(),
            "interview_plan": None,
            "current_topic": None,
            "current_question": None,
            "last_candidate_answer": None,
            "final_recommendation": None,
            "report": None,
            "generated_question": None,
            "controller_decision": None,
            "completed_topics": set(),
            "skip_topic": False,
            "question_type": None,
            "last_question_type": None
        }
        
        logger.info("–ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –∏–Ω—Ç–µ—Ä–≤—å—é")
        
        config = {"recursion_limit": 50}
        final_state = self.app.invoke(initial_state, config=config)
        
        logger.info("–ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        return final_state
    
    def get_report(self, final_state: Dict[str, Any]) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–∞ –∏–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è."""
        return final_state.get("report", "–û—Ç—á–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    def get_recommendation(self, final_state: Dict[str, Any]) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è."""
        return final_state.get("final_recommendation", "UNKNOWN")
